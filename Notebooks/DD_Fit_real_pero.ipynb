{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOAR with SIMsalabim\n",
    "Version 0.1\n",
    "(c) Larry Lueer, Vincent M. Le Corre, i-MEET 2021-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to use BOAR in combination with drift-diffusion modeling to fit of 'fake' JV curves.    \n",
    "To perform the drift-diffusion simulation in the background we use the open-source program [SIMsalabim](https://github.com/kostergroup/SIMsalabim), for more information about SIMsalabim please check the [GitHub repository](https://github.com/kostergroup/SIMsalabim)    \n",
    "Make sure you have SIMsalabim installed before running this Notebook.   \n",
    "\n",
    "Here we are fitting an typical perovskite solar cell with the following structure:  \n",
    "ITO|SnO2|Perovskite|P3HT|Carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate matplotlib widgets\n",
    "%matplotlib inline\n",
    "# comment the next line if you are on the jupyterhub server\n",
    "%matplotlib widget \n",
    "# %matplotlib notebook\n",
    "\n",
    "# Import libraries\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import default_rng\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # comment this out to see warnings\n",
    "\n",
    "# Import boar\n",
    "from boar import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Experimental Data\n",
    "In this section you need to write a function that imports the experimental data. The function should return two array X and y. X is a 2D array with the experimental data. Each row of X is a data point. y is a 1D array with the experimental results. Each row of y is a result vector for the corresponding data point in X.  \n",
    "For example, if you are trying to fit light-intensity dependent JV curves, then X is a 2D array (or list) with in the first column the applied voltage ('Vext') and in the second column the light intensity ('Gfrac') and y is a 1D array (or list) with the JV curves. If you have several light intensities, just append the data to X and y.  \n",
    "\n",
    "```python\n",
    "      Vext   Gfrac             Jext  \n",
    "     _            _          _        _   \n",
    "X = |  0   |   0   |   y =  |  J(0,0)  |  \n",
    "    | 0.1  |   0   |        | J(0.1,1) |  \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |  1   |   0   |        | J(1,0)   |  \n",
    "    |  0   |   1   |        | J(0,1)   |  \n",
    "    | 0.1  |   1   |        | J(0.1,1) |  \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |  .   |   .   |        |   .      | \n",
    "    |_ 1   |   1  _|        |_ J(1,1) _|  \n",
    "      \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data and to the SIMsalabim directory\n",
    "curr_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(curr_dir, '..')) # path to the parent directory\n",
    "path2simu = os.path.join(parent_dir, 'SIMsalabim','SimSS') # path to the SIMsalabim directory\n",
    "# Directory where the results are stored\n",
    "res_dir = os.path.join(curr_dir,'temp') # absolute path to the results directory (note that this will be delete in the last cell of this notebook)\n",
    "dev_par_file = os.path.join(parent_dir,'Example_Data','Shudi','device_parameters_shudi.txt') # absolute path to the device parameter file \n",
    "path2JV = os.path.join(parent_dir,'Example_Data','Shudi') # absolute path to the JV file\n",
    "\n",
    "# Define the fixed parameters and the light intensities\n",
    "X_dimensions = ['Vext','Gfrac']\n",
    "suns = [1]\n",
    "compo = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data and to the SIMsalabim directory\n",
    "# curr_dir = os.getcwd()\n",
    "# # path2JV  = os.path.join(curr_dir,'Example_Data','Chao') # path to the JV files, use this line if Notebook is in the main folder\n",
    "# path2JV  = curr_dir #os.path.join('../','Example_Data','Chao')# path to the JV files, use this line if Notebook is in the Notebooks folder\n",
    "# X_dimensions = ['Vext','Gfrac']\n",
    "# suns = [1]\n",
    "\n",
    "# # Define data to be fitted and path to the data\n",
    "# # Define the path to the SIMsalabim directory and the results directory\n",
    "# path2simu = os.path.join('/home/vlc/Desktop', 'SIMsalabim','SimSS') # absolute path path to the SIMsalabim directory\n",
    "# res_dir = os.path.join(curr_dir,'temp') # path to the results directory, use this line if Notebook is in the main folder\n",
    "# path2dev = os.path.join(curr_dir,'device_parameters.txt') # path to the device directory, use this line if Notebook is in the main folder\n",
    "\n",
    "# compo = '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import JV data\n",
    "def get_JV_exp(compo,suns,path2JV='',Vlim=[],plot=True):\n",
    "    Xs,ys = [],[]\n",
    "    weights_ = []\n",
    "    markers = ['o','s','^','*']\n",
    "    # markers = [None,None,None,None]\n",
    "    lines = [\"-\",\"--\",\"-.\",\":\"]\n",
    "    \n",
    "    JvExp_filename = []\n",
    "    for i in suns:\n",
    "        if i == 'dark':\n",
    "            JvExp_filename.append(os.path.join(path2JV,'MAI'+compo+'_dark.txt'))\n",
    "        else:\n",
    "            JvExp_filename.append(os.path.join(path2JV,'MAI'+compo+'.txt'))\n",
    "    \n",
    "\n",
    "\n",
    "    Gfracs = suns\n",
    "    \n",
    "    err,V,J,Gfrac = [],[],[],[]\n",
    "    X,y = [],[]\n",
    "    \n",
    "    weights = []\n",
    "    idx = 0\n",
    "    for i,G in zip(JvExp_filename,Gfracs):\n",
    "        power,Vs = [],[]\n",
    "        data2fit = pd.read_csv(filepath_or_buffer=os.path.join(i),names=['Vext','Jext'], delim_whitespace=True, header=None, skiprows=1)\n",
    "\n",
    "        # data2fit.dropna(how=\"all\", inplace=True) # drop the empty line at file-end\n",
    "        if Vlim == []:\n",
    "            Vmin = min(data2fit['Vext'])\n",
    "            Vmax = max(data2fit['Vext'])\n",
    "        else:\n",
    "            Vmin = Vlim[0]\n",
    "            Vmax = Vlim[1]\n",
    "        if plot:\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(data2fit['Vext'],data2fit['Jext'],label='Gfrac = '+str(G),marker=markers[idx],color='C'+str(idx),linestyle=lines[idx])\n",
    "            plt.xlim([-1,1.2])\n",
    "            plt.ylim([-240,10])\n",
    "            plt.xlabel('V [V]')\n",
    "            plt.ylabel('Current density [A/m$^2$]')\n",
    "        for index, row in data2fit.iterrows():\n",
    "            if row['Vext'] > Vmin and row['Vext'] < Vmax:\n",
    "                if G=='dark':\n",
    "                    G=0\n",
    "                Vs.append(row['Vext'])\n",
    "                X.append([row['Vext'],G])\n",
    "                y.append(row['Jext'])\n",
    "                if G == 0:\n",
    "                    power.append(1)\n",
    "                else:\n",
    "                    power.append(-row['Vext']*row['Jext'])\n",
    "        \n",
    "        V=data2fit['Vext']\n",
    "        if G > 0:\n",
    "            power = minmax_scale(np.asarray(power), feature_range=(1, 100))\n",
    "        else:\n",
    "            power = np.ones(len(power))\n",
    "        weights = weights + list(power)\n",
    "        if plot:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(Vs,power,label='Gfrac = '+str(G),marker=markers[idx],color='C'+str(idx),linestyle=lines[idx])\n",
    "            plt.xlabel('V [V]')\n",
    "            plt.ylabel('Weight')\n",
    "\n",
    "        \n",
    "        idx += 1\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    V = np.asarray(V)\n",
    "    weights = np.asarray(weights)\n",
    "\n",
    "    if plot:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return X,y,weights\n",
    "\n",
    "Xs,ys,weights_ = get_JV_exp(compo,suns,Vlim=[-0.5,1.15],plot=True,path2JV=path2JV)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Objective Optimization\n",
    "Below we will perform the Bayesian optimization to fit the experimental data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Fitparameters\n",
    "Start_values = {'kdirect':5e-18,'mun_0':2e-8,'mup_0':8e-8,'Nc':5e26,'Gehp':1.28e28,'Bulk_tr':1e20,'Gehp':1.28e28}\n",
    "params = []\n",
    "Nc = Fitparam(name = 'Nc', val = 5e24, relRange = 0, lims=[1e24,1e25],range_type='log',optim_type='log',lim_type='absolute',display_name='N$_{c}$',unit='m$^{-3}$') #real 3e24 \n",
    "params.append(Nc)\n",
    "\n",
    "Bulk_tr = Fitparam(name = 'Bulk_tr', val = 9.625e20 , relRange = 1, lims=[1e20,4e21],range_type='log',optim_type='log',lim_type='absolute',display_name='N$_{Tr}$',unit='m$^{-3}$')\n",
    "params.append(Bulk_tr)\n",
    "\n",
    "kdirect = Fitparam(name = 'kdirect', val = 1e-19 , relRange = 0, lims=[1e-19,1e-16],range_type='log',optim_type='log',lim_type='absolute',display_name='k$_{2}$',unit='m$^{3}$ s$^{-1}$')\n",
    "params.append(kdirect)\n",
    "\n",
    "mun_0 = Fitparam(name = 'mun_0', val = 7e-4 , relRange = 1, lims=[5e-5,1e-2],range_type='log',optim_type='log',lim_type='absolute',display_name='$\\mu_n$',unit='m$^{2}$ V$^{-1}$ s$^{-1}$')\n",
    "params.append(mun_0)\n",
    "\n",
    "mup_0 = Fitparam(name = 'mup_0', val = 6e-4 , relRange = 1, lims=[5e-5,1e-2],range_type='log',optim_type='log',display_name='$\\mu_p$',unit='m$^{2}$ V$^{-1}$ s$^{-1}$')\n",
    "params.append(mup_0)\n",
    "\n",
    "St_L = Fitparam(name = 'St_L', val = 1e6 , relRange = 1, lims=[1e5,1e10],range_type='log',optim_type='log',lim_type='absolute',display_name='S$_{Tr}^{ETL}$',unit='m$^{-2}$')\n",
    "params.append(St_L)\n",
    "\n",
    "St_R = Fitparam(name = 'St_R', val = 1e6 , relRange = 1, lims=[1e5,1e10],range_type='log',optim_type='log',lim_type='absolute',display_name='S$_{Tr}^{HTL}$',unit='m$^{-2}$')\n",
    "params.append(St_R)\n",
    "\n",
    "# If you want to also fit the series and shunt resistance, uncomment the following lines\n",
    "Rseries = Fitparam(name = 'Rseries', val = 1e-5, relRange = 1, lims=[1e-5,1e-3],range_type='log',optim_type='log',lim_type='absolute')\n",
    "params.append(Rseries)\n",
    "\n",
    "# Rshunt = Fitparam(name = 'Rshunt', val = 3e2 , relRange = 1, lims=[1e0,1e3],range_type='log',optim_type='log',lim_type='absolute')\n",
    "# params.append(Rshunt)\n",
    "\n",
    "# W_R = Fitparam(name = 'W_R', val = 0 , relRange = 1, lims=[-0.3,0],range_type='linear',optim_type='linear',lim_type='absolute',display_name='W$_R$ [eV]')\n",
    "# params.append(W_R)\n",
    "# VB_RTL = Fitparam(name = 'VB_RTL', val = 0 , relRange = 1, lims=[-0.5,0],range_type='linear',optim_type='linear',lim_type='absolute',display_name='VB$_{HTL}$ [eV]')\n",
    "# params.append(VB_RTL)\n",
    "\n",
    "# W_L = Fitparam(name = 'W_L', val = 0 , relRange = 1, lims=[0,0.3],range_type='linear',optim_type='linear',lim_type='absolute',display_name='W$_L$ [eV]')\n",
    "# params.append(W_L)\n",
    "\n",
    "# CB_LTL = Fitparam(name = 'CB_LTL', val = 0 , relRange = 1, lims=[0,0.5],range_type='linear',optim_type='linear',lim_type='absolute',display_name='CB$_{ETL}$ [eV]')\n",
    "# params.append(CB_LTL)\n",
    "\n",
    "Nc_LTL = Fitparam(name = 'Nc_LTL', val = 2.7e24 , relRange = 0, lims=[1e24,5e25],range_type='log',optim_type='log',lim_type='absolute',display_name='N$_{c}^{ETL}$',unit='m$^{-3}$')\n",
    "params.append(Nc_LTL)\n",
    "\n",
    "# CNI = Fitparam(name = 'CNI', val = 50e22 , relRange = 0, lims=[10e22,60e22],range_type='log',optim_type='log',lim_type='absolute',display_name='CNI',unit='m$^{-3}$')\n",
    "# params.append(CNI)\n",
    "\n",
    "# CPI = Fitparam(name = 'CPI', val = 50e22 , relRange = 0, lims=[10e22,60e22],range_type='log',optim_type='log',lim_type='absolute',display_name='CPI',unit='m$^{-3}$')\n",
    "# params.append(CPI)\n",
    "\n",
    "Cions = Fitparam(name = 'Cions', val = 5e23 , relRange = 1, lims=[0.5e23,8e23],range_type='log',optim_type='log',lim_type='absolute',display_name='C$_{ions}$',unit='m$^{-3}$')\n",
    "params.append(Cions)\n",
    "\n",
    "\n",
    "Gehp = Fitparam(name = 'Gehp', val = 2.975e27 , relRange = 1, lims=[2.7e27,3.2e27],range_type='log',optim_type='linear',axis_type='log',lim_type='absolute',display_name='G$_{ehp}$ [m$^{-3}$ s$^{-1}$]')\n",
    "params.append(Gehp)\n",
    "\n",
    "params_true = copy.deepcopy(params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the fit\n",
    "# Get experimental data light JV\n",
    "\n",
    "X,y,weights = get_JV_exp(compo,suns,path2JV=path2JV,Vlim=[-0.3,1.15],plot=False)\n",
    "X_dimensions = ['Vext','Gfrac']\n",
    "\n",
    "# Define weighting for the different JV curves\n",
    "use_weighting = True\n",
    "if use_weighting:\n",
    "    weight = weights\n",
    "else:\n",
    "    weight = 1\n",
    "\n",
    "# initialize the simulation agent\n",
    "dda = Drift_diffusion_agent(path2simu=path2simu) \n",
    "fixed_str = ''\n",
    "NewName = '' # name od the device parameter file if you want to use a different one than the default one 'device_parameters.txt'\n",
    "fixed_str = fixed_str + '-maxAcc 0.5 -Vmin -0.35 -Vmax 1.25 -Vstep 0.025 -Vscan -1 -ion_red_rate 0'.format(X[:,0].min()-0.025,X[:,0].max()+0.025) # string to be added to the command line\n",
    "# Define the target\n",
    "target = {'model':partial(dda.DriftDiffusion4fit,X_dimensions=X_dimensions,max_jobs=1,fixed_str=fixed_str,dev_par_fname=dev_par_file),'target_name':'JV','data':{'X':X,'y':y,\n",
    "            'X_dimensions':['Vext','Gfrac'],'X_units':['V','sun'],'y_dimension':'Current density','y_unit':r'$A m^{-2}$'}\n",
    "            ,'params':copy.deepcopy(params), 'weight':weight,'target_weight':1}\n",
    "\n",
    "# Define optimizer\n",
    "mo = MultiObjectiveOptimizer(res_dir=res_dir,params=params,targets=[target]) # initialize the optimizer\n",
    "mo.warmstart = 'none' # 'recall' data from Path2OldXY file\n",
    "\n",
    "# Define the number of iterations for the optimization\n",
    "n_jobs = 4\n",
    "n_jobs_init = 3\n",
    "n_yscale= 18\n",
    "n_initial_points = 30\n",
    "n_BO = 45\n",
    "n_BO_warmstart = 80\n",
    "\n",
    "kwargs = {'check_improvement':'relax','max_loop_no_improvement':15,'xtol':1e-3,'ftol':1e-3}\n",
    "kwargs_posterior = {'Nres':5,'gaussfilt':1,'logscale':False,'vmin':1e-100,'zoom':0,'min_prob':1e-40,'clear_axis':True,'show_points':True,'savefig':True,'figname':'param_posterior' ,'show_fig':True,'figsize':(14,14)}\n",
    "kwargs_plot_obj = {'zscale':'linear','show_fig':False}\n",
    "\n",
    "r = mo.optimize_sko_parallel(n_jobs=n_jobs,n_yscale=n_yscale, n_BO=n_BO, n_initial_points = n_initial_points,n_BO_warmstart=n_BO_warmstart,n_jobs_init=n_jobs_init,kwargs=kwargs,verbose=False,loss='linear',threshold=1000,base_estimator = 'GP',show_objective_func=False,show_posterior=True,kwargs_posterior = kwargs_posterior,kwargs_plot_obj=kwargs_plot_obj)\n",
    "# pf.append(deepcopy(target['params'])) # collects optimized fitparameters\n",
    "rrr = r['r'] # the results dict of the last optimizer.tell()\n",
    "\n",
    "best_params = copy.deepcopy(mo.params) # get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fit results\n",
    "fit_results = []\n",
    "kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':1/10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':True,'figname':'JV_fits_'+compo,'figdir':res_dir}\n",
    "\n",
    "for num,t in enumerate(mo.targets):\n",
    "    kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{compo}')\n",
    "    dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "    X = t['data']['X']\n",
    "    y = t['data']['y']\n",
    "    X_dimensions = t['data']['X_dimensions']\n",
    "    yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "    data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "    fit_results.append(data)\n",
    "\n",
    "# prepare the data for saving\n",
    "param_dict = dda.get_param_dict(mo.params) # get fitparameters (and fixed ones) as dict\n",
    "pout = [[f'{v:.3E}' if isinstance(v,float) else v for _,v in pp.items()] for pp in param_dict] # convert to list of lists\n",
    "\n",
    "\n",
    "# produce output excel file with data, fitparameters and FOMs\n",
    "fn_xlsx = 'MAI_'+compo+'_fits_results.xlsx'\n",
    "namecols = X_dimensions + ['Jexp','Jfit']\n",
    "# delete old file if it exists\n",
    "if os.path.exists(os.path.join(res_dir,fn_xlsx)):\n",
    "    os.remove(os.path.join(res_dir,fn_xlsx))\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(res_dir,fn_xlsx), mode='w') as writer:\n",
    "    for i,t in enumerate(mo.targets):\n",
    "        if 'target_name' in t.keys():\n",
    "            tname = t['target_name']\n",
    "        else: \n",
    "            tname = 'data'\n",
    "        namecols = X_dimensions + [tname+'_exp',tname+'_fit']\n",
    "        df = pd.DataFrame(fit_results[i],columns=namecols)\n",
    "        df.to_excel(writer, sheet_name = tname+f'_{i}')\n",
    "    \n",
    "    df = pd.DataFrame(pout,columns=[k for k in param_dict[0].keys()])\n",
    "    df.to_excel(writer, sheet_name = f'params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "Use curve fit to fine tune the parameters of the model starting from the best parameters found with the Bayesian optimization this help to give a better fit to the data without wasting time with longer Bayesian optimization runs for the fine tuning.\n",
    "Note that using curve_fit alone without the Bayesian optimization is not recommended especially in high dimensional space and wide parameter ranges as it might get stick in local minima or take a long time to converge if the initial guess is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs_curve =  {'ftol':1e-8, 'xtol':1e-6, 'gtol': 1e-8, 'diff_step':0.001,'loss':'linear','maxfev':100}\n",
    "print('Start curve fit')\n",
    "try:\n",
    "    rc = mo.optimize_curvefit(kwargs=kwargs_curve) # fit the best parameters to the data\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Curve fit did not find a better solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fit results\n",
    "fit_results = []\n",
    "kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':1/10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':True,'figname':'JV_fits_curve_fit'+compo,'figdir':res_dir}\n",
    "\n",
    "for num,t in enumerate(mo.targets):\n",
    "    kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{compo}')\n",
    "    dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "    X = t['data']['X']\n",
    "    y = t['data']['y']\n",
    "    X_dimensions = t['data']['X_dimensions']\n",
    "    yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "    data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "    fit_results.append(data)\n",
    "\n",
    "# prepare the data for saving\n",
    "param_dict = dda.get_param_dict(mo.params) # get fitparameters (and fixed ones) as dict\n",
    "pout = [[f'{v:.3E}' if isinstance(v,float) else v for _,v in pp.items()] for pp in param_dict] # convert to list of lists\n",
    "\n",
    "\n",
    "# produce output excel file with data, fitparameters and FOMs\n",
    "fn_xlsx = 'MAI_'+compo+'_fits_results_curve_fit.xlsx'\n",
    "namecols = X_dimensions + ['Jexp','Jfit']\n",
    "# delete old file if it exists\n",
    "if os.path.exists(os.path.join(res_dir,fn_xlsx)):\n",
    "    os.remove(os.path.join(res_dir,fn_xlsx))\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(res_dir,fn_xlsx), mode='w') as writer:\n",
    "    for i,t in enumerate(mo.targets):\n",
    "        if 'target_name' in t.keys():\n",
    "            tname = t['target_name']\n",
    "        else: \n",
    "            tname = 'data'\n",
    "        namecols = X_dimensions + [tname+'_exp',tname+'_fit']\n",
    "        df = pd.DataFrame(fit_results[i],columns=namecols)\n",
    "        df.to_excel(writer, sheet_name = tname+f'_{i}')\n",
    "    \n",
    "    df = pd.DataFrame(pout,columns=[k for k in param_dict[0].keys()])\n",
    "    df.to_excel(writer, sheet_name = f'params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fit parameters after curve fit\n",
    "for p in mo.params:\n",
    "    p.startVal = p.val # reset the start values to the best ones before starting the gradient descent\n",
    "    print(p.name,p.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean output files from simulation folders\n",
    "from boar.SIMsalabim_utils.CleanFolder import *\n",
    "Do_Cleaning = True # Careful, this will delete all files in the folder\n",
    "#path2simu =res_dir\n",
    "if Do_Cleaning:\n",
    "    clean_up_output('tj',path2simu)\n",
    "    clean_up_output('tVG',path2simu)\n",
    "    clean_up_output('JV',path2simu)\n",
    "    clean_up_output('Var',path2simu)\n",
    "    clean_up_output('scPars',path2simu)\n",
    "    clean_up_output('Str4Parallel',path2simu)\n",
    "    clean_up_output('device_parameters_',path2simu)\n",
    "    clean_up_output('logjob',path2simu)\n",
    "    # os.remove(mo.path2oldxy) # remove the old_xy.json file if it exists\n",
    "    # delete warmstart folder if it exists\n",
    "    # if os.path.exists(os.path.join(os.getcwd(),'warmstart/')):\n",
    "    #     shutil.rmtree(os.path.join(os.getcwd(),'warmstart/'))\n",
    "    # delete temp folder if it exists\n",
    "    # if os.path.exists(os.path.join(os.getcwd(),'temp/')):\n",
    "    #     shutil.rmtree(os.path.join(os.getcwd(),'temp/'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf10d86e9ae7e3727a74de00a89e752a3f20ea127cee3e862a4392b6990960f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
