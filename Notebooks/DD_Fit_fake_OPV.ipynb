{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOAR with SIMsalabim\n",
    "Version 1.0.0\n",
    "(c) Vincent M. Le Corre, Larry Lueer, i-MEET 2021-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to use BOAR in combination with drift-diffusion modeling to fit of 'fake' JV curves.  \n",
    "To perform the drift-diffusion simulation in the background we use the open-source program [SIMsalabim](https://github.com/kostergroup/SIMsalabim), for more information about SIMsalabim please check the [GitHub repository](https://github.com/kostergroup/SIMsalabim)  \n",
    "Make sure you have SIMsalabim installed before running this Notebook.  \n",
    "Here we are fitting some 'fake' data that are generated by the drift-diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate matplotlib widgets\n",
    "%matplotlib inline\n",
    "# comment the next line if you are on the jupyterhub server\n",
    "%matplotlib widget \n",
    "# %matplotlib notebook\n",
    "\n",
    "# Import libraries\n",
    "import sys,os\n",
    "from numpy.random import default_rng\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # comment this out to see warnings\n",
    "\n",
    "# Import boar package\n",
    "sys.path.append(os.path.abspath('../')) # add directory containing boar package to path\n",
    "from boar import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to SIMsalabim\n",
    "curr_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(curr_dir, '..')) # path to the parent directory\n",
    "path2simu = os.path.join(parent_dir, 'SIMsalabim','SimSS') # path to the SIMsalabim directory\n",
    "# Directory where the results are stored\n",
    "res_dir = os.path.join(curr_dir,'temp') # absolute path to the results directory (note that this will be delete in the last cell of this notebook)\n",
    "dev_par_file = os.path.join(parent_dir,'Example_Data','Data_test','device_parameters_fake_OPV.txt') # absolute path to the device parameter file (here we use a fake OPV device for illustration purposes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the free parameters to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Fitparameters\n",
    "True_params = {'kdirect':5e-18,'mun_0':2e-8,'mup_0':8e-8,'Nc':5e26,'Gehp':1.28e28,'W_L':0}#,'Rseries':3e-4,'Bulk_tr':1e20,'Gehp':1.28e28}\n",
    "params = []\n",
    "\n",
    "kdirect = Fitparam(name = 'kdirect', val = True_params['kdirect'] , relRange = 1.5, lims=[1e-18,1e-16],range_type='log',optim_type='log',display_name='k$_{2}$',unit='m$^{3}$ s$^{-1}$') \n",
    "params.append(kdirect)\n",
    "\n",
    "mun_0 = Fitparam(name = 'mun_0', val = True_params['mun_0'] , relRange = 1.5, lims=[1e-8,1e-7],range_type='log',optim_type='log',display_name='$\\mu_n$',unit='m$^{2}$ V$^{-1}$ s$^{-1}$')\n",
    "params.append(mun_0)\n",
    "\n",
    "mup_0 = Fitparam(name = 'mup_0', val = True_params['mup_0'] , relRange = 1.5, lims=[1e-8,1e-7],range_type='log',optim_type='log',display_name='$\\mu_p$',unit='m$^{2}$ V$^{-1}$ s$^{-1}$')\n",
    "params.append(mup_0)\n",
    "\n",
    "params_true = copy.deepcopy(params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the structure of the device for SIMsalabim\n",
    "Here we check the structure of the device for SIMsalabim and you can adjust the parameters if needed.\n",
    "\n",
    "For example, if you want to change the thickness of the active layer (AL) you can do this by changing the value of the variable `L` in the cell below.\n",
    "To do so you need to update the value of the variable ParFileDic['L'] and set MakeUpdate to True.\n",
    "\n",
    "By convention LTL is the ETL and RTL is the HTL.\\\n",
    "Note that L is the **total** thickness of the ETL, HTL and active layer, so if you want to change the thickness of the active layer you need to subtract the thickness of the ETL and HTL from the total thickness. \n",
    "Such that:\n",
    "\n",
    "$L_{AL} = L - L_{LTL} - L_{RTL}$\n",
    "\n",
    "To check the name of the parameters in SIMsalabim please refer to the [SIMsalabim documentation](https://github.com/kostergroup/SIMsalabim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize the stack defined for the simulation\n",
    "check_SIMsalabim_input = True\n",
    "# from boar.SIMsalabim_utils.MakeDevParFile import *\n",
    "# from boar.SIMsalabim_utils.GetInputPar import *\n",
    "\n",
    "if check_SIMsalabim_input:\n",
    "    from boar.SIMsalabim_utils.PlotInputPar import *\n",
    "    # Load Device parameters file and update parameters\n",
    "    ParFileDic = ReadParameterFile(dev_par_file) # read the parameters from the file\n",
    "\n",
    "    # Change parameters in the dictionary\n",
    "    ParFileDic['L'] =  100e-9\n",
    "   \n",
    "    MakeUpdate = False # set to True to update the parameters in the file\n",
    "    if MakeUpdate:\n",
    "        UpdateDevParFile(ParFileDic, path2simu) # update the parameters in the file\n",
    "\n",
    "    # Visualize the parameters\n",
    "    fig, axs = plt.subplots(2,2,figsize = (10,8))\n",
    "    plot_input_nrj_diag(ParFileDic,ax=axs[0, 0])\n",
    "    plot_input_mob(ParFileDic,ax=axs[0, 1])\n",
    "    plot_input_dens(ParFileDic,ax=axs[1, 0])\n",
    "    plot_input_SRH_lifetime(ParFileDic,ax=axs[1, 1],y_unit='ns',y2_unit='cm')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare fake data for fitting\n",
    "In the next block we create some fake data with some random noise and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create some fake data\n",
    "Nc = 1 # number of fake datasets\n",
    "V = np.linspace(0,1,100) # voltage\n",
    "Gfrac = np.asarray([0.01,0.5,1]) # Gfrac, i.e. light intensity\n",
    "\n",
    "X_dimensions = ['Vext','Gfrac'] # dimensions of the X array\n",
    "X = np.array([[x,y] for y in Gfrac for x in V ] ) # X array\n",
    "Xplot = Gfrac # X array for plotting\n",
    "\n",
    "# Generate the fake data to fit\n",
    "degradation_run = True\n",
    "True_paramsList = []\n",
    "\n",
    "# define the degradation of kdirect\n",
    "kvals = np.geomspace(5e-18,5e-17,Nc) # simulate degradation of kdirect\n",
    "\n",
    "dda = Drift_diffusion_agent(path2simu=path2simu) # instantiate the agent\n",
    "\n",
    "ys = []\n",
    "True_vals = []\n",
    "True_FOMs = []\n",
    "for kval in kvals:\n",
    "    kdirect.val = kval\n",
    "    True_paramsList.append({'kdirect':kval})\n",
    "    True_params['kdirect'] = kval\n",
    "    # store the true values for plotting later\n",
    "    True_vals.append(True_params.copy())\n",
    "\n",
    "    y = dda.DriftDiffusion_relative(X,params,X_dimensions=X_dimensions, max_jobs=3,dev_par_fname=dev_par_file) # simulate the data\n",
    "    rng = default_rng()#\n",
    "    noise = rng.standard_normal(y.shape) * 1.9\n",
    "    #noise = noise * X[:,1] # try this: higher T - higher noise  \n",
    "    y+=noise # add some noise\n",
    "    ys.append(y)\n",
    "  \n",
    "    plt.plot(X[:,0],y,'o')\n",
    "plt.xlabel('Voltage [V]')\n",
    "plt.ylabel('Current Density [A m$^{-2}$]')\n",
    "# save params list to be modified later to store true values\n",
    "params_true = copy.deepcopy(params)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the datasets one by one\n",
    "pf = [] # list to store the fit results\n",
    "mo = MultiObjectiveOptimizer(params=params,res_dir=res_dir) # instantiate the optimizer\n",
    "\n",
    "n_jobs = 3 \n",
    "n_jobs_init = 3\n",
    "n_yscale= 9 \n",
    "n_initial_points = 60 \n",
    "n_BO = 30 \n",
    "n_BO_warmstart = 60 \n",
    "\n",
    "for ii,y in enumerate(ys):\n",
    "    target = {'model':partial(dda.DriftDiffusion_relative,X_dimensions=X_dimensions,max_jobs=1,dev_par_fname=dev_par_file),'target_name':'JV','data':{'X':X,'y':y,\n",
    "                'X_dimensions':['Vext','Gfrac'],'X_units':['V','sun'],'y_dimension':'Current density','y_unit':r'$A/mÂ²$'},'weight':1,'target_weight':1}\n",
    "    mo.targets = [target]\n",
    "    mo.params = params\n",
    "    mo.warmstart = 'none'\n",
    "    # mo.warmstart = 'None'\n",
    "    mo.SaveOldXY2file = os.path.join(res_dir,'old_XY.json') # path to the file where old points are saved\n",
    "    mo.Path2OldXY = os.path.join(res_dir,'old_XY.json') # path to the file where old points are saved\n",
    "   \n",
    "    kwargs = {'check_improvement':'relax','max_loop_no_improvement':10,'xtol':1e-3,'ftol':1e-3}\n",
    "    kwargs_posterior = {'Nres':10,'gaussfilt':3,'logscale':True,'vmin':1e-100,'zoom':0,'min_prob':1e-40,'clear_axis':False,'True_values':True_vals[ii],'show_points':True,'savefig':False,'figname':'param_posterior'+str(ii),'full_grid':True,'randomize':False}\n",
    "    kwargs_plot_obj = {'zscale':'linear'}\n",
    "\n",
    "    r = mo.optimize_sko_parallel(n_jobs=n_jobs,n_yscale=n_yscale, n_BO=n_BO, n_initial_points = n_initial_points,n_BO_warmstart=n_BO_warmstart,n_jobs_init=n_jobs_init,kwargs=kwargs,verbose=False,loss='linear',threshold=1000,base_estimator = 'GP',show_objective_func=False,show_posterior=True,kwargs_posterior = kwargs_posterior,kwargs_plot_obj=kwargs_plot_obj,)\n",
    "    pf.append(deepcopy(mo.params)) # collects optimized fitparameters\n",
    "    rrr = r['r'] # the results dict of the last optimizer.tell()\n",
    "\n",
    "\n",
    "    #get true parameters and make a params object\n",
    "    for param in params_true:\n",
    "        if param.name in True_paramsList[ii]:\n",
    "            param.val = True_paramsList[ii][param.name]\n",
    "\n",
    "    # plot the fit results\n",
    "    fit_results = []\n",
    "    kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':1/10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':False,'figname':'JV_fits_BO' + str(ii),'figdir':'temp'}\n",
    "\n",
    "    for num,t in enumerate(mo.targets):\n",
    "        kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{num}')\n",
    "        dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "        X = t['data']['X']\n",
    "        y = t['data']['y']\n",
    "        X_dimensions = t['data']['X_dimensions']\n",
    "        yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "        data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "        fit_results.append(data)\n",
    "\n",
    "    # prepare the data for saving\n",
    "    param_dict = dda.get_param_dict(mo.params) # get fitparameters (and fixed ones) as dict\n",
    "    pout = [[f'{v:.3E}' if isinstance(v,float) else v for _,v in pp.items()] for pp in param_dict] # convert to list of lists\n",
    "\n",
    "    save_output = False\n",
    "    if save_output:\n",
    "        # produce output excel file with data, fitparameters and FOMs\n",
    "        fn_xlsx = 'fits_results_BO.xlsx'\n",
    "        namecols = X_dimensions + ['Jexp','Jfit']\n",
    "        # delete old file if it exists\n",
    "        if os.path.exists(os.path.join(res_dir,fn_xlsx)):\n",
    "            os.remove(os.path.join(res_dir,fn_xlsx))\n",
    "\n",
    "        with pd.ExcelWriter(os.path.join(res_dir,fn_xlsx), mode='w') as writer:\n",
    "            for i,t in enumerate(mo.targets):\n",
    "                if 'target_name' in t.keys():\n",
    "                    tname = t['target_name']\n",
    "                else: \n",
    "                    tname = 'data'\n",
    "                namecols = X_dimensions + [tname+'_exp',tname+'_fit']\n",
    "                df = pd.DataFrame(fit_results[i],columns=namecols)\n",
    "                df.to_excel(writer, sheet_name = tname+f'_{i}')\n",
    "            \n",
    "            df = pd.DataFrame(pout,columns=[k for k in param_dict[0].keys()])\n",
    "            df.to_excel(writer, sheet_name = f'params')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fit parameters after BO\n",
    "best_params = deepcopy(mo.params) # get the best parameters\n",
    "\n",
    "for p in mo.params:\n",
    "    p.startVal = p.val # reset the start values to the best ones before starting the gradient descent\n",
    "    print(p.name,p.val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "Use curve fit to fine tune the parameters of the model starting from the best parameters found with the Bayesian optimization this help to give a better fit to the data without wasting time with longer Bayesian optimization runs for the fine tuning.\n",
    "Note that using curve_fit alone without the Bayesian optimization is not recommended especially in high dimensional space and wide parameter ranges as it might get stick in local minima or take a long time to converge if the initial guess is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs_curve =  {'ftol':1e-8, 'xtol':1e-6, 'gtol': 1e-8, 'diff_step':0.001,'loss':'linear','maxfev':100}\n",
    "print('Start curve fit')\n",
    "try:\n",
    "    rc = mo.optimize_curvefit(kwargs=kwargs_curve) # fit the best parameters to the data\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Curve fit did not find a better solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fit results\n",
    "fit_results = []\n",
    "kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':1/10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':False,'figname':'JV_fits_curve_fit' + str(ii),'figdir':'temp'}\n",
    "\n",
    "for num,t in enumerate(mo.targets):\n",
    "    kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{num}')\n",
    "    dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "    X = t['data']['X']\n",
    "    y = t['data']['y']\n",
    "    X_dimensions = t['data']['X_dimensions']\n",
    "    yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "    data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "    fit_results.append(data)\n",
    "\n",
    "# prepare the data for saving\n",
    "param_dict = dda.get_param_dict(mo.params) # get fitparameters (and fixed ones) as dict\n",
    "pout = [[f'{v:.3E}' if isinstance(v,float) else v for _,v in pp.items()] for pp in param_dict] # convert to list of lists\n",
    "\n",
    "save_output = False\n",
    "if save_output:\n",
    "    # produce output excel file with data, fitparameters and FOMs\n",
    "    fn_xlsx = 'fits_results_curve_fit.xlsx'\n",
    "    namecols = X_dimensions + ['Jexp','Jfit']\n",
    "    # delete old file if it exists\n",
    "    if os.path.exists(os.path.join(res_dir,fn_xlsx)):\n",
    "        os.remove(os.path.join(res_dir,fn_xlsx))\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(res_dir,fn_xlsx), mode='w') as writer:\n",
    "        for i,t in enumerate(mo.targets):\n",
    "            if 'target_name' in t.keys():\n",
    "                tname = t['target_name']\n",
    "            else: \n",
    "                tname = 'data'\n",
    "            namecols = X_dimensions + [tname+'_exp',tname+'_fit']\n",
    "            df = pd.DataFrame(fit_results[i],columns=namecols)\n",
    "            df.to_excel(writer, sheet_name = tname+f'_{i}')\n",
    "        \n",
    "        df = pd.DataFrame(pout,columns=[k for k in param_dict[0].keys()])\n",
    "        df.to_excel(writer, sheet_name = f'params')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fit parameters after curve fit\n",
    "for p in mo.params:\n",
    "    p.startVal = p.val # reset the start values to the best ones before starting the gradient descent\n",
    "    print(p.name,p.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean output files from simulation folders\n",
    "from boar.SIMsalabim_utils.CleanFolder import *\n",
    "\n",
    "Do_Cleaning = True # Careful, this will delete all files in the folder\n",
    "if Do_Cleaning:\n",
    "    clean_up_output('tj',path2simu)\n",
    "    clean_up_output('tVG',path2simu)\n",
    "    clean_up_output('JV',path2simu)\n",
    "    clean_up_output('Var',path2simu)\n",
    "    clean_up_output('scPars',path2simu)\n",
    "    clean_up_output('Str4Parallel',path2simu)\n",
    "    clean_up_output('log',path2simu)\n",
    "    # os.remove(mo.path2oldxy) # remove the old_xy.json file if it exists\n",
    "    # delete warmstart folder if it exists\n",
    "    if os.path.exists(os.path.join(os.getcwd(),'warmstart/')):\n",
    "        shutil.rmtree(os.path.join(os.getcwd(),'warmstart/'))\n",
    "    # delete temp folder if it exists\n",
    "    if os.path.exists(res_dir):\n",
    "        shutil.rmtree(res_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf10d86e9ae7e3727a74de00a89e752a3f20ea127cee3e862a4392b6990960f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
