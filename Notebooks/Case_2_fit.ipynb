{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOAR with SIMsalabim\n",
    "Version 1.0.0\n",
    "(c) Vincent M. Le Corre, Larry Lueer, i-MEET 2021-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to use BOAR in combination with drift-diffusion modeling to fit of 'fake' JV curves.  \n",
    "To perform the drift-diffusion simulation in the background we use the open-source program [SIMsalabim](https://github.com/kostergroup/SIMsalabim), for more information about SIMsalabim please check the [GitHub repository](https://github.com/kostergroup/SIMsalabim)  \n",
    "Make sure you have SIMsalabim installed before running this Notebook.  \n",
    "Here we are fitting some 'fake' data that are generated by the drift-diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate matplotlib widgets\n",
    "%matplotlib inline\n",
    "%matplotlib widget \n",
    "\n",
    "# Import libraries\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # comment this out to see warnings\n",
    "\n",
    "# Import boar package\n",
    "from boar import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student_number = 12 # change this to your student number\n",
    "Case_number = 2 # change this to the case number you are working on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to SIMsalabim\n",
    "curr_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(curr_dir, '..')) # path to the parent directory\n",
    "path2simu = os.path.join(parent_dir, 'SIMsalabim','SimSS') # path to the SIMsalabim directory\n",
    "# Directory where the results are stored\n",
    "res_dir = os.path.join(curr_dir,'temp') # absolute path to the results directory (note that this will be delete in the last cell of this notebook)\n",
    "dev_par_file = os.path.join(parent_dir,'Data_2_fit',f'Case_{Case_number}',f'Case_{Case_number}_device_parameters.txt') # absolute path to the device parameter file (here we use a fake OPV device for illustration purposes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the free parameters to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Fitparameters\n",
    "True_params = {'kdirect':5e-18,'mun_0':2e-8,'mup_0':8e-8,'Nc':5e26,'Gehp':1.28e28,'W_L':0}#,'Rseries':3e-4,'Bulk_tr':1e20,'Gehp':1.28e28}\n",
    "params = []\n",
    "\n",
    "kdirect = Fitparam(name = 'kdirect', val = True_params['kdirect'] , relRange = 1.5, lims=[1e-18,1e-15],range_type='log',optim_type='log',display_name='k$_{2}$',unit='m$^{3}$ s$^{-1}$') \n",
    "params.append(kdirect)\n",
    "\n",
    "mun_0 = Fitparam(name = 'mun_0', val = True_params['mun_0'] , relRange = 1.5, lims=[5e-9,5e-7],range_type='log',optim_type='log',display_name='$\\mu_n$',unit='m$^{2}$ V$^{-1}$ s$^{-1}$')\n",
    "params.append(mun_0)\n",
    "\n",
    "mup_0 = Fitparam(name = 'mup_0', val = True_params['mup_0'] , relRange = 1.5, lims=[5e-9,5e-7],range_type='log',optim_type='log',display_name='$\\mu_p$',unit='m$^{2}$ V$^{-1}$ s$^{-1}$')\n",
    "params.append(mup_0)\n",
    "\n",
    "Gehp = Fitparam(name = 'Gehp', val = True_params['Gehp'] , relRange = 1.5, lims=[1.25e28,1.3e28],range_type='log',optim_type='lin',display_name='G$_{ehp}$',unit='m$^{-3}$ s$^{-1}$')\n",
    "params.append(Gehp)\n",
    "params_true = copy.deepcopy(params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the structure of the device for SIMsalabim\n",
    "Here we check the structure of the device for SIMsalabim and you can adjust the parameters if needed.\n",
    "\n",
    "For example, if you want to change the thickness of the active layer (AL) you can do this by changing the value of the variable `L` in the cell below.\n",
    "To do so you need to update the value of the variable ParFileDic['L'] and set MakeUpdate to True.\n",
    "\n",
    "By convention LTL is the ETL and RTL is the HTL.\\\n",
    "Note that L is the **total** thickness of the ETL, HTL and active layer, so if you want to change the thickness of the active layer you need to subtract the thickness of the ETL and HTL from the total thickness. \n",
    "Such that:\n",
    "\n",
    "$L_{AL} = L - L_{LTL} - L_{RTL}$\n",
    "\n",
    "To check the name of the parameters in SIMsalabim please refer to the [SIMsalabim documentation](https://github.com/kostergroup/SIMsalabim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize the stack defined for the simulation\n",
    "from boar.SIMsalabim_utils.PlotInputPar import *\n",
    "\n",
    "# Load Device parameters file and update parameters\n",
    "ParFileDic = ReadParameterFile(dev_par_file) # read the parameters from the file\n",
    "\n",
    "# Visualize the parameters\n",
    "fig, axs = plt.subplots(2,2,figsize = (10,8))\n",
    "plot_input_nrj_diag(ParFileDic,ax=axs[0, 0])\n",
    "plot_input_mob(ParFileDic,ax=axs[0, 1])\n",
    "plot_input_dens(ParFileDic,ax=axs[1, 0])\n",
    "plot_input_SRH_lifetime(ParFileDic,ax=axs[1, 1],y_unit='ns',y2_unit='cm')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data to fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data to fit\n",
    "data2fit = pd.read_csv(os.path.join(parent_dir,'Data_2_fit',f'Case_{Case_number}',f'Case_{Case_number}_student_{Student_number}.txt'),delim_whitespace=True)\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(data2fit['Vext'],data2fit['Jext']/10)\n",
    "plt.xlabel('Voltage [V]')\n",
    "plt.ylabel('Current density [mA cm$^2$]')\n",
    "\n",
    "Gfrac = np.ones(len(data2fit['Vext']))\n",
    "X = np.asarray(data2fit['Vext'].values)\n",
    "# concatenate the Gfrac in the X array\n",
    "X = np.vstack((X,Gfrac)).T\n",
    "y = np.asarray(data2fit['Jext'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the datasets one by one\n",
    "pf = [] # list to store the fit results\n",
    "mo = MultiObjectiveOptimizer(params=params,res_dir=res_dir) # instantiate the optimizer\n",
    "X_dimensions = ['Vext','Gfrac'] # dimensions of the X array\n",
    "dda = Drift_diffusion_agent(path2simu=path2simu) # instantiate the agent\n",
    "\n",
    "n_jobs = 3 \n",
    "n_jobs_init = 3\n",
    "n_yscale= 9 \n",
    "n_initial_points = 30 \n",
    "n_BO = 30 \n",
    "\n",
    "\n",
    "target = {'model':partial(dda.DriftDiffusion_relative,X_dimensions=X_dimensions,max_jobs=1,dev_par_fname=dev_par_file),'target_name':'JV','data':{'X':X,'y':y,\n",
    "            'X_dimensions':['Vext','Gfrac'],'X_units':['V','suns'],'y_dimension':'Current density','y_unit':r'$A/mÂ²$'},'weight':1,'target_weight':1}\n",
    "mo.targets = [target]\n",
    "mo.params = params\n",
    "mo.warmstart = 'None'\n",
    "\n",
    "\n",
    "# kwargs_posterior = {'Nres':10,'N':3,'logscale':True,'vmin':1e-100,'zoom':0,'min_prob':1e-40,'clear_axis':False,'True_values':None,'show_points':True,'savefig':False,'figname':'param_posterior'+str(ii),'full_grid':True,'randomize':False}\n",
    "kwargs_posterior = {'show_points':True,'savefig':False,'figname':'param_posterior','full_grid':True,'randomize':False}\n",
    "\n",
    "r = mo.optimize_sko_parallel(n_jobs=n_jobs,n_yscale=n_yscale, n_BO=n_BO, n_initial_points = n_initial_points,n_jobs_init=n_jobs_init,verbose=False,loss='linear',threshold=1000,base_estimator = 'GP',show_objective_func=False,show_posterior=True,kwargs_posterior = kwargs_posterior)\n",
    "pf.append(deepcopy(mo.params)) # collects optimized fitparameters\n",
    "rrr = r['r'] # the results dict of the last optimizer.tell()\n",
    "\n",
    "\n",
    "# plot the fit results\n",
    "fit_results = []\n",
    "kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':1/10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':False,'figname':'JV_fits_BO','figdir':'temp'}\n",
    "\n",
    "for num,t in enumerate(mo.targets):\n",
    "    kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{num}')\n",
    "    dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "    X = t['data']['X']\n",
    "    y = t['data']['y']\n",
    "    X_dimensions = t['data']['X_dimensions']\n",
    "    yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "    data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "    fit_results.append(data)\n",
    "\n",
    "# prepare the data for saving\n",
    "param_dict = dda.get_param_dict(mo.params) # get fitparameters (and fixed ones) as dict\n",
    "pout = [[f'{v:.3E}' if isinstance(v,float) else v for _,v in pp.items()] for pp in param_dict] # convert to list of lists\n",
    "\n",
    "save_output = False\n",
    "if save_output:\n",
    "    # produce output excel file with data, fitparameters and FOMs\n",
    "    fn_xlsx = 'fits_results_BO.xlsx'\n",
    "    namecols = X_dimensions + ['Jexp','Jfit']\n",
    "    # delete old file if it exists\n",
    "    if os.path.exists(os.path.join(res_dir,fn_xlsx)):\n",
    "        os.remove(os.path.join(res_dir,fn_xlsx))\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(res_dir,fn_xlsx), mode='w') as writer:\n",
    "        for i,t in enumerate(mo.targets):\n",
    "            if 'target_name' in t.keys():\n",
    "                tname = t['target_name']\n",
    "            else: \n",
    "                tname = 'data'\n",
    "            namecols = X_dimensions + [tname+'_exp',tname+'_fit']\n",
    "            df = pd.DataFrame(fit_results[i],columns=namecols)\n",
    "            df.to_excel(writer, sheet_name = tname+f'_{i}')\n",
    "        \n",
    "        df = pd.DataFrame(pout,columns=[k for k in param_dict[0].keys()])\n",
    "        df.to_excel(writer, sheet_name = f'params')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fit parameters after BO\n",
    "best_params = deepcopy(mo.params) # get the best parameters\n",
    "\n",
    "for p in mo.params:\n",
    "    p.startVal = p.val # reset the start values to the best ones before starting the gradient descent\n",
    "    print(p.name,p.val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "Use curve fit to fine tune the parameters of the model starting from the best parameters found with the Bayesian optimization this help to give a better fit to the data without wasting time with longer Bayesian optimization runs for the fine tuning.\n",
    "Note that using curve_fit alone without the Bayesian optimization is not recommended especially in high dimensional space and wide parameter ranges as it might get stick in local minima or take a long time to converge if the initial guess is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs_curve =  {'ftol':1e-8, 'xtol':1e-6, 'gtol': 1e-8, 'diff_step':0.001,'loss':'linear','maxfev':100}\n",
    "print('Start curve fit')\n",
    "try:\n",
    "    rc = mo.optimize_curvefit(kwargs=kwargs_curve) # fit the best parameters to the data\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Curve fit did not find a better solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fit results\n",
    "fit_results = []\n",
    "kwargs_plot_res = {'x_scaling':1,'xaxis_label':'Voltage [V]','xscale_type':'linear','y_scaling':1/10,'yaxis_label':'Current density [mA cm$^2$]','yscale_type':'linear','norm_data':False,'delog':False,'figsize':(10,10),'savefig':False,'figname':'JV_fits_curve_fit','figdir':'temp'}\n",
    "\n",
    "for num,t in enumerate(mo.targets):\n",
    "    kwargs_plot_res['figname'] = os.path.join(res_dir,t['target_name']+f'_fit_{num}')\n",
    "    dda.plot_fit_res(t,mo.params,'Vext',xlim=[],ylim=[],kwargs=kwargs_plot_res)\n",
    "\n",
    "    X = t['data']['X']\n",
    "    y = t['data']['y']\n",
    "    X_dimensions = t['data']['X_dimensions']\n",
    "    yfit = t['model'](X,params,X_dimensions=X_dimensions) # get the best fits\n",
    "\n",
    "    data = np.concatenate((X, y.reshape(len(y),1), yfit.reshape(len(yfit),1)), axis=1)\n",
    "    fit_results.append(data)\n",
    "\n",
    "# prepare the data for saving\n",
    "param_dict = dda.get_param_dict(mo.params) # get fitparameters (and fixed ones) as dict\n",
    "pout = [[f'{v:.3E}' if isinstance(v,float) else v for _,v in pp.items()] for pp in param_dict] # convert to list of lists\n",
    "\n",
    "save_output = False\n",
    "if save_output:\n",
    "    # produce output excel file with data, fitparameters and FOMs\n",
    "    fn_xlsx = 'fits_results_curve_fit.xlsx'\n",
    "    namecols = X_dimensions + ['Jexp','Jfit']\n",
    "    # delete old file if it exists\n",
    "    if os.path.exists(os.path.join(res_dir,fn_xlsx)):\n",
    "        os.remove(os.path.join(res_dir,fn_xlsx))\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(res_dir,fn_xlsx), mode='w') as writer:\n",
    "        for i,t in enumerate(mo.targets):\n",
    "            if 'target_name' in t.keys():\n",
    "                tname = t['target_name']\n",
    "            else: \n",
    "                tname = 'data'\n",
    "            namecols = X_dimensions + [tname+'_exp',tname+'_fit']\n",
    "            df = pd.DataFrame(fit_results[i],columns=namecols)\n",
    "            df.to_excel(writer, sheet_name = tname+f'_{i}')\n",
    "        \n",
    "        df = pd.DataFrame(pout,columns=[k for k in param_dict[0].keys()])\n",
    "        df.to_excel(writer, sheet_name = f'params')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fit parameters after curve fit\n",
    "for p in mo.params:\n",
    "    p.startVal = p.val # reset the start values to the best ones before starting the gradient descent\n",
    "    print(p.name,p.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean output files from simulation folders\n",
    "from boar.SIMsalabim_utils.CleanFolder import *\n",
    "\n",
    "Do_Cleaning = True # Careful, this will delete all files in the folder\n",
    "if Do_Cleaning:\n",
    "    clean_up_output('tj',path2simu)\n",
    "    clean_up_output('tVG',path2simu)\n",
    "    clean_up_output('JV',path2simu)\n",
    "    clean_up_output('Var',path2simu)\n",
    "    clean_up_output('scPars',path2simu)\n",
    "    clean_up_output('Str4Parallel',path2simu)\n",
    "    clean_up_output('log',path2simu)\n",
    "    # os.remove(mo.path2oldxy) # remove the old_xy.json file if it exists\n",
    "    # delete warmstart folder if it exists\n",
    "    if os.path.exists(os.path.join(os.getcwd(),'warmstart/')):\n",
    "        shutil.rmtree(os.path.join(os.getcwd(),'warmstart/'))\n",
    "    # delete temp folder if it exists\n",
    "    if os.path.exists(res_dir):\n",
    "        shutil.rmtree(res_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf10d86e9ae7e3727a74de00a89e752a3f20ea127cee3e862a4392b6990960f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
